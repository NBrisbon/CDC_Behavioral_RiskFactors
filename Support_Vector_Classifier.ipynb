{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "import statsmodels.api as sm\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>_AGE_G</th>\n",
       "      <th>_BMI5CAT</th>\n",
       "      <th>_EDUCAG</th>\n",
       "      <th>_INCOMG</th>\n",
       "      <th>_RFDRHV5</th>\n",
       "      <th>_PACAT1</th>\n",
       "      <th>_RFHLTH</th>\n",
       "      <th>_HCVU651</th>\n",
       "      <th>EMPLOY1</th>\n",
       "      <th>VETERAN3</th>\n",
       "      <th>MARITAL</th>\n",
       "      <th>ADDEPEV2</th>\n",
       "      <th>POORHLTH</th>\n",
       "      <th>PHYSHLTH</th>\n",
       "      <th>MENTHLTH</th>\n",
       "      <th>MENTHLTH2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEX  _AGE_G  _BMI5CAT  _EDUCAG  _INCOMG  _RFDRHV5  _PACAT1  _RFHLTH  \\\n",
       "0  0.0     6.0       1.0      1.0      4.0       0.0      1.0      1.0   \n",
       "1  1.0     6.0       1.0      1.0      5.0       0.0      1.0      1.0   \n",
       "2  1.0     6.0       1.0      0.0      4.0       0.0      4.0      1.0   \n",
       "3  0.0     6.0       1.0      0.0      1.0       0.0      2.0      0.0   \n",
       "4  0.0     6.0       0.0      0.0      1.0       0.0      4.0      0.0   \n",
       "\n",
       "   _HCVU651  EMPLOY1  VETERAN3  MARITAL  ADDEPEV2  POORHLTH  PHYSHLTH  \\\n",
       "0       1.0      0.0       1.0      0.0       0.0       0.0       0.0   \n",
       "1       1.0      0.0       0.0      1.0       0.0       0.0       0.0   \n",
       "2       1.0      0.0       0.0      1.0       0.0       0.0       0.0   \n",
       "3       1.0      0.0       0.0      0.0       1.0       0.0       0.0   \n",
       "4       1.0      0.0       0.0      0.0       0.0      14.0      14.0   \n",
       "\n",
       "   MENTHLTH  MENTHLTH2  \n",
       "0       0.0        0.0  \n",
       "1       0.0        0.0  \n",
       "2       0.0        0.0  \n",
       "3       0.0        0.0  \n",
       "4       0.0        0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 50)\n",
    "LLCP2 = pd.read_csv(r'C:\\Users\\Nick\\Desktop\\GitProjects\\LLCP_Project\\LLCP2.csv')\n",
    "LLCP2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into train/test sets (70/30 split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = LLCP2[['SEX','_AGE_G','_BMI5CAT','_EDUCAG','_INCOMG','_RFDRHV5','_PACAT1','_RFHLTH','_HCVU651','EMPLOY1',\n",
    "           'VETERAN3','MARITAL','ADDEPEV2','POORHLTH','PHYSHLTH']].values\n",
    "\n",
    "y = LLCP2['MENTHLTH2'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows/columns in X_test dataset:  (135005, 15)\n",
      "Number of rows/columns in y_test dataset:  (135005,)\n",
      "Number of rows/columns in X_train dataset:  (315011, 15)\n",
      "Number of rows/columns in y_train dataset:  (315011,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# describes info about train and test set \n",
    "print(\"Number of rows/columns in X_test dataset: \", X_test.shape) \n",
    "print(\"Number of rows/columns in y_test dataset: \", y_test.shape) \n",
    "print(\"Number of rows/columns in X_train dataset: \", X_train.shape) \n",
    "print(\"Number of rows/columns in y_train dataset: \", y_train.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nick\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:244: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# sklearn.svm.SVC(C=1.0, kernel='rbf', degree=3, gamma=0.0, coef0=0.0, shrinking=True, probability=False,\n",
    "                #tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, random_state=None)\n",
    "\n",
    "SVC_model = svm.SVC(C=1, kernel='linear', probability=True, random_state=0, class_weight={0:1,1:2}, \n",
    "                    max_iter=10000)\n",
    "SVC_model.fit(X_train, y_train)\n",
    "y_pred = SVC_model.predict(X_test)\n",
    "probs = SVC_model.predict_proba(X_test)\n",
    "probs = probs[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the accuracy reports and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with unbalanced data:\n",
    "\n",
    "## The data is unbalanced, indicted by two things: \n",
    "\n",
    "### (1) MENTHLTH2 value counts show twice as many '0' than '1' rows\n",
    "### (2) The accuracy scores for the '1' values are far lower than the '0', showing the model is biased. It's good at predicting 'Good Mental Health', but not 'Poor Mental Health'.\n",
    "\n",
    "### There are various re-sampling methods for dealing with unbalanced data. We will utilize the 'Under-sampling' technique. This technique drops rows at random from the 'majority class', or the over-represented value. In this case, the '0' rows will be dropped at random until both value's are equal. This can lead to a loss of information, if there is not enough data. Since we have almost 500,000 total rows, this should not be a significant problem. I'll be re-running this with other re-sampling methods in the future for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLCP2.MENTHLTH2.value_counts().plot(kind='bar', title='Count (MENTHLTH2)');\n",
    "LLCP2['MENTHLTH2'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, re-check value counts for the target...you can see twice as many '0' values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class count\n",
    "count_class_0, count_class_1 = LLCP2.MENTHLTH2.value_counts()\n",
    "\n",
    "# Divide by class\n",
    "Good_MH = LLCP2[LLCP2['MENTHLTH2'] == 0]\n",
    "Poor_MH = LLCP2[LLCP2['MENTHLTH2'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, we want to divide the target by value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Good_MH_under = Good_MH.sample(count_class_1)\n",
    "LLCP2_under = pd.concat([Good_MH_under, Poor_MH], axis=0)\n",
    "\n",
    "print('Random under-sampling:')\n",
    "print(LLCP2_under.MENTHLTH2.value_counts())\n",
    "\n",
    "LLCP2_under.MENTHLTH2.value_counts().plot(kind='bar', title='Count (MENTHLTH2)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can see above that we now have an equal amount of observations for both values of the target MENTHLTH2. We did lose a lot of information using this method, however, we still have a pretty large dataset to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Under-Sampled Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's re-run the model now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_under = LLCP2_under[['SEX','_AGE_G','_BMI5CAT','_EDUCAG','_INCOMG','_RFDRHV5','_PACAT1','_RFHLTH','_HCVU651','EMPLOY1',\n",
    "           'VETERAN3','MARITAL','ADDEPEV2','POORHLTH','PHYSHLTH']].values\n",
    "\n",
    "y_under = LLCP2_under['MENTHLTH2'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_under, X_test_under, y_train_under, y_test_under = train_test_split(X_under, y_under, test_size=0.3, random_state=0)\n",
    "\n",
    "# describes info about train and test set \n",
    "print(\"Number of rows/columns in X_test_under dataset: \", X_test_under.shape) \n",
    "print(\"Number of rows/columns in y_test_under dataset: \", y_test_under.shape) \n",
    "print(\"Number of rows/columns in X_train_under dataset: \", X_train_under.shape) \n",
    "print(\"Number of rows/columns in y_train_under dataset: \", y_train_under.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_train_under, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train_under_scaled = scaler.fit_transform(X_train_under)\n",
    "X_test_under_scaled = scaler.transform(X_test_under)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn.svm.SVC(C=1.0, kernel='rbf', degree=3, gamma=0.0, coef0=0.0, shrinking=True, probability=False,\n",
    "                #tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, random_state=None)\n",
    "\n",
    "SVC_under = svm.SVC(C=1, kernel='linear', random_state=0)\n",
    "SVC_under.fit(X_train_under_scaled, y_train_under)\n",
    "y_pred_under = SVC_under.predict(X_test_under_scaled)   #yields predicted class 0/1\n",
    "probs_under = SVC_under.predict_proba(X_test_under_scaled)\n",
    "probs_under = probs_under[:,1]    #yields probability of either class 0-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test_under,y_pred_under))\n",
    "print(classification_report(y_test_under,y_pred_under))\n",
    "print(accuracy_score(y_test_under, y_pred_under))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The accuracy score here is similar, but slightly better than the score for logistic regression (71% vs 70%). The score is lower than the previous RFC model using the unbalanced data, however, this model shows decent results for both classes.\n",
    "\n",
    "### Confusion matrix shows that:\n",
    "#### True positive:    32648     _(We predicted a positive result and it was positive)_\n",
    "#### True negative:    28229     _(We predicted a negative result and it was negative)_\n",
    "#### False positive:   10057      _(We predicted a positive result and it was negative)_\n",
    "#### False negative:   14674     _(We predicted a negative result and it was positive)_\n",
    "\n",
    "### So, this model makes more correct predictions, than not and the false negative rate seems a bit higher than the false positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, let's run a ROC plot and get the area under the curve score (AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = roc_auc_score(y_test_under, probs_under)\n",
    "fpr, tpr, thresholds = roc_curve(y_test_under, probs_under)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(fpr, tpr, label='Random Forest Classifier (area = %0.3f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('ROC')\n",
    "plt.show()\n",
    "print('AUC: %.3f' % roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC for both the Random Forest Classifier and Logistic Regression were very similar. Both had Area Under the Curve (AUC) at .77. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Over-Sampled Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SMOTE, we over-sample the minority class (MENTHLTH2 = 1) and take care to test/train split before preoceeding with re-sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# setting up testing and training sets\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "sm = SMOTE(sampling_strategy='minority', random_state=0)\n",
    "X_train_over, y_train_over = sm.fit_sample(X_train3, y_train3)\n",
    "\n",
    "# describes info about train and test set \n",
    "print(\"Number of rows/columns in X_test3 dataset: \", X_test3.shape) \n",
    "print(\"Number of rows/columns in y_test3 dataset: \", y_test3.shape) \n",
    "print(\"Number of rows/columns in X_train_over dataset: \", X_train_over.shape) \n",
    "print(\"Number of rows/columns in y_train_over dataset: \", y_train_over.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_train3, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_train_over, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train_over_scaled = scaler.fit_transform(X_train_over)\n",
    "X_test3_scaled = scaler.transform(X_test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see above, we have 215,000 observations for each value of the target now in the training set. \n",
    "\n",
    "### Let's run another Random Forest Classifier with this Over-Sampled data and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn.svm.SVC(C=1.0, kernel='rbf', degree=3, gamma=0.0, coef0=0.0, shrinking=True, probability=False,\n",
    "                #tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, random_state=None)\n",
    "\n",
    "SVC_over = svm.SVC(C=1, kernel='linear', random_state=0)\n",
    "SVC_over.fit(X_train_over_scaled, y_train_over)\n",
    "y_pred_over = SVC_over.predict(X_test3_scaled)   #yields predicted class 0/1\n",
    "probs_over = SVC_over.predict_proba(X_test3_scaled)\n",
    "probs_over = probs_over[:,1]    #yields probability of either class 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test3,y_pred_over))\n",
    "print(classification_report(y_test3,y_pred_over))\n",
    "print(accuracy_score(y_test3, y_pred_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = roc_auc_score(y_test3, probs_over)\n",
    "fpr, tpr, thresholds = roc_curve(y_test3, probs_over)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(fpr, tpr, label='Random Forest Classifier (area = %0.3f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('ROC')\n",
    "plt.show()\n",
    "print('AUC: %.3f' % roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can see that this model is clearly the best so far. The accuracy is up to 79% and precision/recal for both values of the target are also highest for this model. The AUC of .85 beats the other three models all at .77. It seems that Random Forest Classifier may be better suited than Logistic Regression for over-sampled data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
